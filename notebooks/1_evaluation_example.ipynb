{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "20e45c3b",
   "metadata": {},
   "source": [
    "# Evaluation example"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ac48dca",
   "metadata": {},
   "source": [
    "In this notebook we will demonstrate how to use the PES, MES and JES acquisition functions. All of these acquisition functions rely on Monte Carlo samples of the of the maximum and/or maximizer. Once these samples are obtained, we then initialize the variables that do not depend on the test location. For the PES acquisition function we initialize the expectation propagation caches, whilst for the MES and JES we compute the box-decompositions. After initialization, the acquisition functions can then be evaluated like any other acquisition function in BoTorch."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10974a29",
   "metadata": {},
   "source": [
    "## Initialize a problem"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d837a22b",
   "metadata": {},
   "source": [
    "We will initialize the ZDT1 benchmark with two-dimensional inputs and outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a6dc378c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "from botorch.utils.sampling import draw_sobol_samples\n",
    "from botorch.test_functions.multi_objective import ZDT1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "77851993",
   "metadata": {},
   "outputs": [],
   "source": [
    "d = 2\n",
    "M = 2\n",
    "n = 6\n",
    "\n",
    "problem = ZDT1(dim=d, num_objectives=M, noise_std=0, negate=True)\n",
    "bounds = problem.bounds\n",
    "\n",
    "# `n x d`\n",
    "train_X = draw_sobol_samples(bounds=bounds, n=n, q=1, seed=123).squeeze(-2)\n",
    "train_Y = problem(train_X)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a537ada2",
   "metadata": {},
   "source": [
    "## Fit a GP"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "966bb926",
   "metadata": {},
   "source": [
    "We fit a Gaussian process using the standard tools in BoTorch. As advised in the BoTorch documentation, we normalize the inputs and standardize the outputs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c0c2ac80",
   "metadata": {},
   "outputs": [],
   "source": [
    "from botorch.models.gp_regression import SingleTaskGP\n",
    "from botorch.utils.transforms import unnormalize, normalize\n",
    "from botorch.models.transforms.outcome import Standardize\n",
    "from gpytorch.mlls.exact_marginal_log_likelihood import ExactMarginalLogLikelihood\n",
    "from botorch.fit import fit_gpytorch_model\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "a4240522",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fit_gp(tX, tY, num_outputs):\n",
    "    model = SingleTaskGP(tX, tY, outcome_transform=Standardize(m=num_outputs))\n",
    "    mll = ExactMarginalLogLikelihood(model.likelihood, model)\n",
    "    fit_gpytorch_model(mll)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "146f9144",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken = 0.29\n"
     ]
    }
   ],
   "source": [
    "init_time = time.time()\n",
    "model = fit_gp(normalize(train_X, bounds), train_Y, M)\n",
    "standard_bounds = torch.zeros(2, d)\n",
    "standard_bounds[1] = 1.0\n",
    "print(\"Time taken = {:4.2f}\".format(time.time() - init_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b5c30bfd",
   "metadata": {},
   "source": [
    "## Sample Pareto set and front"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dcf7aee9",
   "metadata": {},
   "source": [
    "To sample the Pareto optimal set we first generate approximate samples from the Gaussian process using random Fourier features and then we optimize these paths using a multi-objective solver (NSGA2 from pymoo). We execute this step in sequence i.e. we sample the paths and optimize them one by one. From analysing the wall-times, we notice that it would be very advantageous to parallelize this step in practice.\n",
    "\n",
    "The multi-objective solver NSGA2 relies on a random heuristic to generate an approximation to the optimal inputs and outputs. As a result, the number of optimal points that are generate cannot be guaranteed a priori. To overcome this issue, we oversample the number Pareto points and then select a subset of these points. The default setting of the method we wrote  selects this subset randomly. Alternatively, we consider a more principled strategy where a fraction of this subset is chosen by picking the points that greedily maximize the hypervolume spanned by the already queried locations. In particular, if we have a function sample $f_s$ and an oversampled approximate Pareto set $\\mathbb{X}^*_s$, then we will first select the point $x^*_1 = \\text{argmax}_{x \\in \\mathbb{X}} \\text{HV}(\\{f_s(x_t)\\}_{t=1,\\dots,n} \\cup \\{f_s(x)\\})$ and then $x^*_2 = \\text{argmax}_{x \\in \\mathbb{X}} \\text{HV}(\\{f_s(x_t)\\}_{t=1,\\dots,n} \\cup \\{f_s(x^*_1)\\}\\cup \\{f_s(x)\\})$ etc. The reference point is estimated using the observations $\\{y_t\\}_{t=1,\\dots,n}$ - we set $r^{(m)} = \\min(y_t^{(m)}) - 0.1 |\\min y_t^{(m)}|$ for objectives $m=1,\\dots,M$."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6c95c223",
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from jes.utils.sample_pareto import sample_pareto_sets_and_fronts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "8449c4d9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken = 14.36\n"
     ]
    }
   ],
   "source": [
    "num_pareto_samples = 10\n",
    "num_pareto_points = 10\n",
    "# this controls how many points of `num_pareto_points` is chosen greedily using the hypervolume truncation strategy\n",
    "num_greedy = 10\n",
    "\n",
    "num_rff_features = 500\n",
    "generations = 500\n",
    "pop_size = 100\n",
    "\n",
    "init_time = time.time()\n",
    "# `num_pareto_samples x num_fantasies x num_pareto_points x M`\n",
    "# this extra `num_fantasies` dimension arises from pending points for greedy batch optimization\n",
    "# in this example `num_fantasies = 1`\n",
    "pareto_sets, pareto_fronts = sample_pareto_sets_and_fronts(\n",
    "    model=model,\n",
    "    num_pareto_samples=num_pareto_samples,\n",
    "    num_pareto_points=num_pareto_points,\n",
    "    bounds=standard_bounds,\n",
    "    generations=generations,\n",
    "    num_rff_features=num_rff_features,\n",
    "    pop_size=pop_size,\n",
    "    num_greedy=num_greedy,\n",
    ")\n",
    "print(\"Time taken = {:4.2f}\".format(time.time() - init_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9cfd070e",
   "metadata": {},
   "source": [
    "## Initialization"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1d0c7370",
   "metadata": {},
   "source": [
    "We now initialize the acquisition functions. For the MES and JES we compute the box decomposition, whilst for PES we compute the initial expectation propagation cache."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "65b5deb9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from jes.acquisition.jes import qLowerBoundJointEntropySearch, compute_box_decomposition\n",
    "from jes.acquisition.mes import qLowerBoundMaximumEntropySearch\n",
    "from jes.acquisition.pes import qPredictiveEntropySearch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "f5661382",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken = 0.01\n"
     ]
    }
   ],
   "source": [
    "# Computing the box decomposition\n",
    "# `num_pareto_samples x num_fantasies x 2 x J x M`\n",
    "init_time = time.time()\n",
    "hypercell_bounds = compute_box_decomposition(pareto_fronts)\n",
    "print(\"Time taken = {:4.2f}\".format(time.time() - init_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1a242142",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken = 0.02\n"
     ]
    }
   ],
   "source": [
    "# We compute the JES-LB\n",
    "estimation_type = \"Lower bound\"\n",
    "init_time = time.time()\n",
    "jes_lb = qLowerBoundJointEntropySearch(\n",
    "    model=model,\n",
    "    pareto_sets=pareto_sets.squeeze(1),\n",
    "    pareto_fronts=pareto_fronts.squeeze(1),\n",
    "    hypercell_bounds=hypercell_bounds.squeeze(1),\n",
    "    estimation_type=\"Lower bound\",\n",
    ")\n",
    "print(\"Time taken = {:4.2f}\".format(time.time() - init_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "539ab9df",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken = 0.00\n"
     ]
    }
   ],
   "source": [
    "# We compute the MES-LB\n",
    "estimation_type = \"Lower bound\"\n",
    "init_time = time.time()\n",
    "mes_lb = qLowerBoundMaximumEntropySearch(\n",
    "    model=model,\n",
    "    pareto_fronts=pareto_fronts.squeeze(1),\n",
    "    hypercell_bounds=hypercell_bounds.squeeze(1),\n",
    "    estimation_type=\"Lower bound\",\n",
    ")\n",
    "print(\"Time taken = {:4.2f}\".format(time.time() - init_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "3a164523",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time taken = 2.16\n"
     ]
    }
   ],
   "source": [
    "# We initialize the EP cache\n",
    "init_time = time.time()\n",
    "pes = qPredictiveEntropySearch(\n",
    "    model=model,\n",
    "    pareto_sets=pareto_sets.squeeze(1),\n",
    "    ep_jitter=1e-4,\n",
    "    test_jitter=1e-4,\n",
    "    threshold=1e-2\n",
    ")\n",
    "print(\"Time taken = {:4.2f}\".format(time.time() - init_time))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c65cb06f",
   "metadata": {},
   "source": [
    "## Evaluate"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ed0e67fc",
   "metadata": {},
   "source": [
    "We can now evaluate the acquisition functions at a batch of locations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c1f0b9d8",
   "metadata": {},
   "outputs": [],
   "source": [
    "n_test = 100\n",
    "batch_size = 5\n",
    "seed = 1234\n",
    "test_X = draw_sobol_samples(bounds=bounds, n=n_test, q=batch_size, seed=seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "0183e871",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ -9.0774, -12.1666, -10.1464, -10.1997, -10.1681, -10.4998,  -9.2664,\n",
      "        -11.9596,  -8.0653, -10.3604, -11.1240,  -9.8985, -11.7575, -12.1313,\n",
      "         -9.6138,  -8.9834,  -9.9995, -12.7739,  -9.0370, -11.4104, -11.7735,\n",
      "         -9.2464, -10.2028, -10.6667,  -8.9171, -10.1871, -11.7773,  -9.8830,\n",
      "        -10.0824, -10.3526, -12.8204, -11.7996, -11.5821,  -9.7403,  -9.7470,\n",
      "        -11.7474,  -9.2701, -11.9155,  -9.6426,  -9.7572,  -8.7004, -12.3717,\n",
      "         -9.4911, -10.6211, -11.6930,  -8.7440, -10.7825,  -9.7010,  -8.7058,\n",
      "        -10.5795, -12.6451,  -9.9520, -10.1552, -12.0376,  -8.2568, -10.6634,\n",
      "         -9.2616, -12.9105, -10.7465,  -8.9769,  -9.4299,  -9.6034, -11.2351,\n",
      "        -10.7372,  -9.2206, -11.9250, -11.7260,  -7.8976, -12.4670, -11.0933,\n",
      "        -10.5075,  -9.7642,  -8.6875, -11.4382, -10.0694, -10.4519, -12.3360,\n",
      "        -10.1776, -10.3725,  -9.8017, -10.7588,  -9.5486,  -9.5540,  -9.7506,\n",
      "         -9.1716, -11.7311, -10.6793,  -9.8526,  -8.1019, -12.1292, -10.1319,\n",
      "        -10.2219, -11.0310,  -9.2982,  -9.4543, -12.3669,  -9.5403, -10.4798,\n",
      "        -10.4570, -10.1101], grad_fn=<SubBackward0>)\n",
      "Time taken = 0.04\n"
     ]
    }
   ],
   "source": [
    "init_time = time.time()\n",
    "print(jes_lb(test_X))\n",
    "print(\"Time taken = {:4.2f}\".format(time.time() - init_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "68dd993c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([-11.6999, -12.5003, -11.2780, -11.6609, -11.0977, -11.9452, -11.1982,\n",
      "        -12.7046, -10.7308, -11.3326, -12.3554, -11.8627, -14.0877, -12.5369,\n",
      "        -10.9026, -11.0002, -12.4424, -13.2998, -11.6729, -13.1946, -12.6508,\n",
      "        -11.1712, -11.6212, -12.3059, -11.0074, -11.1602, -12.4468, -11.1556,\n",
      "        -11.3715, -11.7498, -13.6827, -12.9498, -12.2901, -11.8124, -11.2890,\n",
      "        -13.0058, -11.0494, -12.6766, -10.9869, -11.8919, -10.7744, -12.7729,\n",
      "        -11.0625, -12.4014, -12.3543, -11.5733, -12.4339, -10.9562, -11.2962,\n",
      "        -11.7668, -13.3956, -11.6350, -11.2368, -12.7964, -10.6532, -11.2663,\n",
      "        -11.6603, -13.6331, -11.9053, -11.1679, -12.3714, -11.1575, -12.6725,\n",
      "        -11.6661, -12.1231, -12.7770, -12.3458, -10.6192, -13.3746, -11.6870,\n",
      "        -11.5835, -11.6394, -11.3216, -12.6022, -11.3167, -11.6287, -13.2982,\n",
      "        -12.6712, -11.9769, -11.6322, -12.1041, -10.9645, -10.9766, -11.1582,\n",
      "        -12.2845, -12.0460, -11.8410, -11.2711, -11.1270, -13.1053, -10.9592,\n",
      "        -12.1878, -11.7070, -11.3526, -11.5498, -13.0491, -11.7472, -12.0111,\n",
      "        -11.5481, -11.3509], grad_fn=<SubBackward0>)\n",
      "Time taken = 0.03\n"
     ]
    }
   ],
   "source": [
    "init_time = time.time()\n",
    "print(mes_lb(test_X))\n",
    "print(\"Time taken = {:4.2f}\".format(time.time() - init_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ed292b5b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tensor([ 0.5128, -0.1866,  0.3816,  0.3773,  0.0487,  0.2961,  0.4858,  0.1068,\n",
      "         1.0844,  0.1814,  0.4016,  0.8720,  0.7532,  0.0884,  0.3194,  0.6954,\n",
      "         0.7721,  0.1287,  0.8209,  0.6240,  0.0026,  0.5942,  0.3557,  0.3945,\n",
      "         0.8359, -0.1281,  0.0248,  0.2640,  0.2886,  0.0454,  0.0632,  0.0781,\n",
      "        -0.1589,  0.4392,  0.4241,  0.3995,  0.6551,  0.1709,  0.2821,  0.9445,\n",
      "         0.5449, -0.0344,  0.6479,  0.4335,  0.1960,  0.7700,  0.3575, -0.0533,\n",
      "         0.6716,  0.4965,  0.0992,  0.7156, -0.0893,  0.0651,  0.9099, -0.1999,\n",
      "         1.0964,  0.3815,  0.3047,  0.6562,  1.0769,  0.6974,  0.5181,  0.3434,\n",
      "         0.9912,  0.0855,  0.0721,  1.4436,  0.3145, -0.3540,  0.1771,  0.7035,\n",
      "         0.9442,  0.2592,  0.2763,  0.1227,  0.2823,  1.2711,  0.6235,  0.6896,\n",
      "         0.1389,  0.3004,  0.5626,  0.3945,  0.7621, -0.0689,  0.1027,  0.1444,\n",
      "         1.2955,  0.3585, -0.0632,  0.6410,  0.0802,  0.8384,  0.6173,  0.0443,\n",
      "         0.6066,  0.4240,  0.1586,  0.2322], grad_fn=<MulBackward0>)\n",
      "Time taken = 0.37\n"
     ]
    }
   ],
   "source": [
    "init_time = time.time()\n",
    "print(pes(test_X))\n",
    "print(\"Time taken = {:4.2f}\".format(time.time() - init_time))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8f65052e",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
